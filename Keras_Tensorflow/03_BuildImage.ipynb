{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Image\n",
    "\n",
    "In this notebook, we show the following steps for deploying a web service using AML:\n",
    "\n",
    "- Create an image\n",
    "- Test image locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "from azureml.core.model import Model\n",
    "from azureml._model_management._util import (get_docker_client, pull_docker_image)\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.image import ContainerImage\n",
    "from dotenv import get_key, find_dotenv\n",
    "from testing_utilities import to_img, plot_predictions, get_auth, wait_until_ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = get_key(env_path, 'resource_group')\n",
    "model_name = 'resnet_model'\n",
    "image_name = get_key(env_path, 'image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workspace\n",
    "Load existing workspace from the config file info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace\n",
      "azuremlresourcegroup\n",
      "eastus\n",
      "32cf04de-62b6-46b8-b31a-863d7fd95678\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config(auth=get_auth())\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create yml file to be used in the image\n",
    "conda_pack = [\"tensorflow-gpu==1.14.0\"]\n",
    "requirements = [\"keras==2.2.0\",\"Pillow==5.2.0\", \"azureml-defaults\", \"azureml-contrib-services\" ,\"toolz==0.9.0\"] \n",
    "\n",
    "imgenv = CondaDependencies.create(conda_packages=conda_pack,pip_packages=requirements)\n",
    "with open(\"img_env.yml\", \"w\") as f:\n",
    "    f.write(imgenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"driver.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"img_env.yml\",\n",
    "                                                  description = \"Image for AKS Deployment Tutorial\",\n",
    "                                                  tags = {\"name\":\"AKS\",\"project\":\"AML\"}, \n",
    "                                                  dependencies = [\"resnet152.py\"],\n",
    "                                                  enable_gpu = True\n",
    "                                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running....................................................................................................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image kerasimage:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# create image. It may take upto 15-20 minutes. \n",
    "image = ContainerImage.create(name = image_name,\n",
    "                              # this is the model object\n",
    "                              models = [ws.models[model_name]],                              \n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can find the logs of image creation\n",
    "# image.image_build_log_uri\n",
    "\n",
    "# You can get the image object when not creating a new image\n",
    "image = ws.images['kerasimage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test image locally\n",
    "- Pull the image from ACR registry to local host \n",
    "- Start a container\n",
    "- Test API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContainerURL:workspace0deabba7.azurecr.io/kerasimage:1\n",
      "Servername: workspace0deabba7\n",
      "Username: workspace0deabba7\n",
      "Password: Jw5mTEOc/Yku9PVdzq8/Lzx/uIsMSrP/\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config(auth=get_auth())\n",
    "# Getting your container details\n",
    "container_reg = ws.get_details()[\"containerRegistry\"]\n",
    "reg_name=container_reg.split(\"/\")[-1]\n",
    "container_url = \"\\\"\" + image.image_location + \"\\\",\"\n",
    "subscription_id = ws.subscription_id\n",
    "\n",
    "client = ContainerRegistryManagementClient(ws._auth,subscription_id)\n",
    "result= client.registries.list_credentials(resource_group, reg_name, custom_headers=None, raw=False)\n",
    "username = result.username\n",
    "password = result.passwords[0].value\n",
    "print('ContainerURL:{}'.format(image.image_location))\n",
    "print('Servername: {}'.format(reg_name))\n",
    "print('Username: {}'.format(username))\n",
    "print('Password: {}'.format(password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = get_docker_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling image from ACR (this may take a few minutes depending on image size)...\n",
      "\n",
      "1: Pulling from kerasimage\n",
      "Digest: sha256:f69dba33ca1171f75b71d955a21f311593c25a2ae2fd76071c29c287ad9df073\n",
      "Status: Image is up to date for workspace0deabba7.azurecr.io/kerasimage:1\n"
     ]
    }
   ],
   "source": [
    "pull_docker_image(dc, image.image_location, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workspace0deabba7.azurecr.io/kerasimage:1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.image_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure port 80 is not occupied\n",
    "container_labels = {'containerName': 'kerasgpu'}\n",
    "container = dc.containers.run(image.image_location, \n",
    "                                         detach=True, \n",
    "                                         ports={'5001/tcp': 80},\n",
    "                                         labels=container_labels,\n",
    "                                         runtime='nvidia' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-container-runtime\r\n"
     ]
    }
   ],
   "source": [
    "!which nvidia-container-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\r\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\r\n"
     ]
    }
   ],
   "source": [
    "!apt install nvidia-container-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-20T11:50:41,893393522+00:00 - nginx/run \n",
      "\n",
      "2020-04-20T11:50:41,892172354+00:00 - gunicorn/run \n",
      "\n",
      "2020-04-20T11:50:41,893621716+00:00 - rsyslog/run \n",
      "\n",
      "2020-04-20T11:50:41,900579533+00:00 - iot-server/run \n",
      "\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "\n",
      "2020-04-20T11:50:41,968059658+00:00 - iot-server/finish 1 0\n",
      "\n",
      "2020-04-20T11:50:41,969181628+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "\n",
      "Starting gunicorn 19.9.0\n",
      "\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "\n",
      "Using worker: sync\n",
      "\n",
      "worker timeout is set to 300\n",
      "\n",
      "Booting worker with pid: 49\n",
      "\n",
      "Initializing logger\n",
      "\n",
      "Starting up app insights client\n",
      "\n",
      "Starting up request id generator\n",
      "\n",
      "Starting up app insight hooks\n",
      "\n",
      "Invoking user's init function\n",
      "\n",
      "2020-04-20 11:50:48,495 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\n",
      "\tInnerException None\n",
      "\n",
      "\tErrorResponse \n",
      "\n",
      "{\n",
      "\n",
      "    \"error\": {\n",
      "\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "\n",
      "    }\n",
      "\n",
      "}, switching offline: False\n",
      "\n",
      "2020-04-20 11:50:48,495 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "\n",
      "2020-04-20 11:50:48,495 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\n",
      "\tInnerException RunEnvironmentException:\n",
      "\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\n",
      "\tInnerException None\n",
      "\n",
      "\tErrorResponse \n",
      "\n",
      "{\n",
      "\n",
      "    \"error\": {\n",
      "\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "\n",
      "    }\n",
      "\n",
      "}\n",
      "\n",
      "\tErrorResponse \n",
      "\n",
      "{\n",
      "\n",
      "    \"error\": {\n",
      "\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "\n",
      "    }\n",
      "\n",
      "}\n",
      "\n",
      "2020-04-20 11:50:48,495 | azureml.core.model | DEBUG | version is None. Latest version is 1\n",
      "\n",
      "2020-04-20 11:50:48,495 | azureml.core.model | DEBUG | Found model path at azureml-models/resnet_model/1/model_resnet_weights.h5\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:71: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:514: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4076: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:171: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:178: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "\n",
      "\n",
      "2020-04-20 11:50:48.529144: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "\n",
      "2020-04-20 11:50:48.535304: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593995000 Hz\n",
      "\n",
      "2020-04-20 11:50:48.536085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55af851726f0 executing computations on platform Host. Devices:\n",
      "\n",
      "2020-04-20 11:50:48.536116: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\n",
      "2020-04-20 11:50:48.538213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "\n",
      "2020-04-20 11:50:48.754079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55af851978a0 executing computations on platform CUDA. Devices:\n",
      "\n",
      "2020-04-20 11:50:48.754122: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "\n",
      "2020-04-20 11:50:48.755084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "\n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "\n",
      "pciBusID: e3d6:00:00.0\n",
      "\n",
      "2020-04-20 11:50:48.755346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "\n",
      "2020-04-20 11:50:48.757001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "\n",
      "2020-04-20 11:50:48.758561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "\n",
      "2020-04-20 11:50:48.759110: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "\n",
      "2020-04-20 11:50:48.760829: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "\n",
      "2020-04-20 11:50:48.761861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "\n",
      "2020-04-20 11:50:48.765786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "\n",
      "2020-04-20 11:50:48.767530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "\n",
      "2020-04-20 11:50:48.767578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "\n",
      "2020-04-20 11:50:48.768878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "\n",
      "2020-04-20 11:50:48.768902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "\n",
      "2020-04-20 11:50:48.768911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "\n",
      "2020-04-20 11:50:48.770643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: e3d6:00:00.0, compute capability: 6.0)\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1811: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3900: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "\n",
      "\n",
      "From /opt/miniconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3904: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "\n",
      "\n",
      "Model loading time: 27045.35 ms\n",
      "\n",
      "Model loaded and container ready\n"
     ]
    }
   ],
   "source": [
    "for log_msg in container.logs(stream=True):\n",
    "    str_msg = log_msg.decode('UTF8')\n",
    "    print(str_msg)\n",
    "    if \"Model loading time:\" in str_msg:\n",
    "        print('Model loaded and container ready')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = docker.APIClient()\n",
    "details = client.inspect_container(container.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DockerClient' object has no attribute 'APIClient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-63934c6f5c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/deployment_aml/lib/python3.6/site-packages/docker/client.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    203\u001b[0m                      \u001b[0;34m\"object APIClient. See the low-level API section of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                      \"documentation for more details.\")\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DockerClient' object has no attribute 'APIClient'"
     ]
    }
   ],
   "source": [
    "dc.APIClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details['NetworkSettings']['Ports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'5001/tcp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-349fed1ffb75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mservice_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NetworkSettings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ports'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'5001/tcp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HostIp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mservice_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NetworkSettings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ports'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'5001/tcp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HostPort'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '5001/tcp'"
     ]
    }
   ],
   "source": [
    "service_ip = details['NetworkSettings']['Ports']['5001/tcp'][0]['HostIp']\n",
    "service_port = details['NetworkSettings']['Ports']['5001/tcp'][0]['HostPort']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a few seconds for the application to spin up and then check that everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking service on {} port {}'.format(service_ip, service_port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint=\"http://__service_ip:__service_port\"\n",
    "endpoint = endpoint.replace('__service_ip', service_ip)\n",
    "endpoint = endpoint.replace('__service_port', service_port)\n",
    "\n",
    "max_attempts = 50\n",
    "output_str = wait_until_ready(endpoint, max_attempts)\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl 'http://{service_ip}:{service_port}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEURL = \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/220px-Lynx_lynx_poing.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_img(IMAGEURL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('220px-Lynx_lynx_poing.jpg', 'rb') as f:\n",
    "    img_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time r = requests.post('http://0.0.0.0:80/score', files={'image': img_data})\n",
    "print(r)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = (\n",
    "    \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/220px-Lynx_lynx_poing.jpg\",\n",
    "    \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/Roadster_2.5_windmills_trimmed.jpg\",\n",
    "    \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/Harmony_of_the_Seas_(ship,_2016)_001.jpg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing_utilities import read_image_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://0.0.0.0:80/score\"\n",
    "results = [\n",
    "    requests.post(url, files={'image': read_image_from(img).read()}) for img in images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(images, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = list(map(lambda img: read_image_from(img).read(), images)) # Retrieve the images and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_results = list()\n",
    "for img in image_data:\n",
    "    res=%timeit -r 1 -o -q requests.post(url, files={'image': img})\n",
    "    timer_results.append(res.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average time taken: {0:4.2f} ms\".format(10 ** 3 * np.mean(timer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Containers:\r\n",
      "d3cc0103bfb5e40b011c807534ca1f8fd5e4a82d7da13e139c3e17be95f48791\r\n",
      "e26ed9a82b2fa819954f5106df9ac85fc343b2edae0932d056f24cdad3bee3fe\r\n",
      "66e8e0d4af177415df9b552f023d83205c4a8614650bb01d73ae19ded72db00f\r\n",
      "44464e170e5403f43cb8cfb69437b54a176cc5a63314a286b54dd7f3ea9c0dee\r\n",
      "1bf383737ee2754347a110b592094ae820dd3a177deab0bf056cf9009c2512ef\r\n",
      "\r\n",
      "Total reclaimed space: 71.72MB\r\n"
     ]
    }
   ],
   "source": [
    "# remove stopped container\n",
    "!docker system prune -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move on to [Create kubenetes cluster and deploy web service](04_DeployOnAKS.ipynb) with the image we just built."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "deployment_aml",
   "language": "python",
   "name": "conda-env-deployment_aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
