{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model Driver\n",
    "\n",
    "In this notebook, we will develop the API that will call our model. This module initializes the model, transforms the input so that it is in the appropriate format and defines the scoring method that will produce the predictions. The API will expect the input to be passed as an image. Once a request is received, the API will convert load the image preprocess it and pass it to the model. There are two main functions in the API: init() and run(). The init() function loads the model and returns a scoring function. The run() function processes the images and uses the first function to score them.\n",
    "\n",
    "    Note: Always make sure you don't have any lingering notebooks running (Shutdown previous notebooks). Otherwise it may cause GPU memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from dotenv import set_key, find_dotenv\n",
    "import logging\n",
    "from testing_utilities import get_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda/envs/deployment_aml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras:  2.2.0\n",
      "Tensorflow:  1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras: \", keras.__version__)\n",
    "print(\"Tensorflow: \", tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and save driver script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile driver.py\n",
    "\n",
    "from resnet152 import ResNet152\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from azureml.contrib.services.aml_request import rawhttp\n",
    "from azureml.core.model import Model\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "from toolz import compose\n",
    "import numpy as np\n",
    "import timeit as t\n",
    "from PIL import Image, ImageOps\n",
    "import logging\n",
    "\n",
    "_NUMBER_RESULTS = 3\n",
    "\n",
    "\n",
    "def _image_ref_to_pil_image(image_ref):\n",
    "    \"\"\" Load image with PIL (RGB)\n",
    "    \"\"\"\n",
    "    return Image.open(image_ref).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def _pil_to_numpy(pil_image):\n",
    "    img = ImageOps.fit(pil_image, (224, 224), Image.ANTIALIAS)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def _create_scoring_func():\n",
    "    \"\"\" Initialize ResNet 152 Model\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    start = t.default_timer()\n",
    "    model_name = \"resnet_model\"\n",
    "    model_path = Model.get_model_path(model_name)\n",
    "    model = ResNet152()\n",
    "    model.load_weights(model_path)\n",
    "    end = t.default_timer()\n",
    "\n",
    "    loadTimeMsg = \"Model loading time: {0} ms\".format(round((end - start) * 1000, 2))\n",
    "    logger.info(loadTimeMsg)\n",
    "\n",
    "    def call_model(img_array_list):\n",
    "        img_array = np.stack(img_array_list)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        preds = model.predict(img_array)\n",
    "        # Converting predictions to float64 since we are able to serialize float64 but not float32\n",
    "        preds = decode_predictions(preds.astype(np.float64), top=_NUMBER_RESULTS)\n",
    "        return preds\n",
    "\n",
    "    return call_model\n",
    "\n",
    "\n",
    "def get_model_api():\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    scoring_func = _create_scoring_func()\n",
    "\n",
    "    def process_and_score(images_dict):\n",
    "        \"\"\" Classify the input using the loaded model\n",
    "        \"\"\"\n",
    "        start = t.default_timer()\n",
    "        logger.info(\"Scoring {} images\".format(len(images_dict)))\n",
    "        transform_input = compose(_pil_to_numpy, _image_ref_to_pil_image)\n",
    "        transformed_dict = {\n",
    "            key: transform_input(img_ref) for key, img_ref in images_dict.items()\n",
    "        }\n",
    "        preds = scoring_func(list(transformed_dict.values()))\n",
    "        preds = dict(zip(transformed_dict.keys(), preds))\n",
    "        end = t.default_timer()\n",
    "\n",
    "        logger.info(\"Predictions: {0}\".format(preds))\n",
    "        logger.info(\"Predictions took {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "        return (preds, \"Computed in {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "\n",
    "    return process_and_score\n",
    "\n",
    "\n",
    "def init():\n",
    "    \"\"\" Initialise the model and scoring function\n",
    "    \"\"\"\n",
    "    global process_and_score\n",
    "    process_and_score = get_model_api()\n",
    "\n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "    \"\"\" Make a prediction based on the data passed in using the preloaded model\n",
    "    \"\"\"\n",
    "    if request.method == 'POST':\n",
    "        return process_and_score(request.files)\n",
    "    if request.method == 'GET':\n",
    "        resp_body = {\n",
    "            \"azEnvironment\": \"Azure\",\n",
    "            \"location\": \"westus2\",\n",
    "            \"osType\": \"Ubuntu 16.04\",\n",
    "            \"resourceGroupName\": \"\",\n",
    "            \"resourceId\": \"\",\n",
    "            \"sku\": \"\",\n",
    "            \"subscriptionId\": \"\",\n",
    "            \"uniqueId\": \"PythonMLRST\",\n",
    "            \"vmSize\": \"\",\n",
    "            \"zone\": \"\",\n",
    "            \"isServer\": False,\n",
    "            \"version\": \"\"\n",
    "        }\n",
    "        return resp_body\n",
    "    return AMLResponse(\"bad request\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the driverÂ¶\n",
    "We test the driver by passing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run driver.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:testing_utilities:Trying to create Workspace with CLI Authentication\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core.util:attempting to read file /home/riversand/.azure/accessTokens.json as utf-8-sig\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - Authority:Performing instance discovery: ...\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - Authority:Performing static instance discovery\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - Authority:Authority validated via static instance discovery\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - TokenRequest:Getting token from cache with refresh if necessary.\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - CacheDriver:finding with query keys: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - CacheDriver:Looking for potential cache entries: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - CacheDriver:Found 2 potential entries.\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - CacheDriver:Resource specific token found.\n",
      "DEBUG:adal-python:a6846883-7e08-4bc0-9ee8-a0bb99e5cf01 - CacheDriver:Returning token from cache lookup, AccessTokenId: b'FcU7/YFvV7OsI3mXIaHEOK+1MDQ9CH9hgni2i8EC8tk=', RefreshTokenId: b'9kJefConsGAGG6FoD0LFr4Bzi1GeBwtQ64HigSzzC2U='\n",
      "DEBUG:azureml.core.workspace:No config file directly found, starting search from /home/riversand/notebooks/dlmodeldeploy/Keras_Tensorflow directory, for config.json file name to be present in .azureml subdirectory\n",
      "INFO:azureml.core.workspace:Found the config file in: /home/riversand/notebooks/dlmodeldeploy/Keras_Tensorflow/.azureml/config.json\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - Authority:Performing instance discovery: ...\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - Authority:Performing static instance discovery\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - Authority:Authority validated via static instance discovery\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - TokenRequest:Getting token from cache with refresh if necessary.\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - CacheDriver:finding with query keys: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - CacheDriver:Looking for potential cache entries: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - CacheDriver:Found 2 potential entries.\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - CacheDriver:Resource specific token found.\n",
      "DEBUG:adal-python:f8cb6557-bd3f-4290-9b9a-235363df16e0 - CacheDriver:Returning token from cache lookup, AccessTokenId: b'FcU7/YFvV7OsI3mXIaHEOK+1MDQ9CH9hgni2i8EC8tk=', RefreshTokenId: b'9kJefConsGAGG6FoD0LFr4Bzi1GeBwtQ64HigSzzC2U='\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - Authority:Performing instance discovery: ...\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - Authority:Performing static instance discovery\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - Authority:Authority validated via static instance discovery\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - TokenRequest:Getting token from cache with refresh if necessary.\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - CacheDriver:finding with query keys: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - CacheDriver:Looking for potential cache entries: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - CacheDriver:Found 2 potential entries.\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - CacheDriver:Resource specific token found.\n",
      "DEBUG:adal-python:c5a66f50-f9bf-433e-a31a-e0f44ad50810 - CacheDriver:Returning token from cache lookup, AccessTokenId: b'FcU7/YFvV7OsI3mXIaHEOK+1MDQ9CH9hgni2i8EC8tk=', RefreshTokenId: b'9kJefConsGAGG6FoD0LFr4Bzi1GeBwtQ64HigSzzC2U='\n",
      "DEBUG:msrest.universal_http.requests:Configuring retry: max_retries=4, backoff_factor=0.8, max_backoff=90\n",
      "DEBUG:msrest.service_client:Accept header absent and forced to application/json\n",
      "DEBUG:msrest.universal_http:Configuring redirects: allow=True, max=30\n",
      "DEBUG:msrest.universal_http:Configuring request: timeout=100, verify=True, cert=None\n",
      "DEBUG:msrest.universal_http:Configuring proxies: ''\n",
      "DEBUG:msrest.universal_http:Evaluate proxies against ENV settings: True\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): management.azure.com:443\n",
      "DEBUG:urllib3.connectionpool:https://management.azure.com:443 \"GET /subscriptions/32cf04de-62b6-46b8-b31a-863d7fd95678/resourceGroups/azuremlresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/workspace?api-version=2018-11-19 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace\n",
      "azuremlresourcegroup\n",
      "eastus\n",
      "32cf04de-62b6-46b8-b31a-863d7fd95678\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config(auth=get_auth())\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model and score against an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:azureml.core.run:Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}, switching offline: False\n",
      "DEBUG:azureml.core.run:Could not load the run context and allow_offline set to False\n",
      "DEBUG:azureml.core.model:RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - Authority:Performing instance discovery: ...\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - Authority:Performing static instance discovery\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - Authority:Authority validated via static instance discovery\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - TokenRequest:Getting token from cache with refresh if necessary.\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - CacheDriver:finding with query keys: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - CacheDriver:Looking for potential cache entries: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - CacheDriver:Found 2 potential entries.\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - CacheDriver:Resource specific token found.\n",
      "DEBUG:adal-python:a3f1d6ae-02ef-43e4-b514-d9648f8a7e41 - CacheDriver:Returning token from cache lookup, AccessTokenId: b'FcU7/YFvV7OsI3mXIaHEOK+1MDQ9CH9hgni2i8EC8tk=', RefreshTokenId: b'9kJefConsGAGG6FoD0LFr4Bzi1GeBwtQ64HigSzzC2U='\n",
      "DEBUG:msrest.universal_http.requests:Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\n",
      "INFO:azureml._restclient.clientbase:Created a worker pool for first use\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): eastus.modelmanagement.azureml.net:443\n",
      "DEBUG:urllib3.connectionpool:https://eastus.modelmanagement.azureml.net:443 \"GET /api/subscriptions/32cf04de-62b6-46b8-b31a-863d7fd95678/resourceGroups/azuremlresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/workspace/models?api-version=2018-11-19&orderBy=CreatedAtDesc&count=1&name=resnet_model HTTP/1.1\" 200 None\n",
      "DEBUG:azureml.core.model:Found model version 1\n",
      "DEBUG:azureml.AssetsClient.query_by_id-async:False:[START]\n",
      "DEBUG:msrest.service_client:Accept header absent and forced to application/json\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - Authority:Performing instance discovery: ...\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - Authority:Performing static instance discovery\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - Authority:Authority validated via static instance discovery\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - TokenRequest:Getting token from cache with refresh if necessary.\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - CacheDriver:finding with query keys: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - CacheDriver:Looking for potential cache entries: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - CacheDriver:Found 2 potential entries.\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - CacheDriver:Resource specific token found.\n",
      "DEBUG:adal-python:7d42f1cc-3d9a-46c9-9295-26397c7cddbd - CacheDriver:Returning token from cache lookup, AccessTokenId: b'FcU7/YFvV7OsI3mXIaHEOK+1MDQ9CH9hgni2i8EC8tk=', RefreshTokenId: b'9kJefConsGAGG6FoD0LFr4Bzi1GeBwtQ64HigSzzC2U='\n",
      "DEBUG:msrest.http_logger:Request URL: 'https://eastus.modelmanagement.azureml.net/api/subscriptions/32cf04de-62b6-46b8-b31a-863d7fd95678/resourceGroups/azuremlresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/workspace/assets/4e40bbe0ed9e4642a872717c960ccaaa?api-version=2018-11-19'\n",
      "DEBUG:msrest.http_logger:Request method: 'GET'\n",
      "DEBUG:msrest.http_logger:Request headers:\n",
      "DEBUG:msrest.http_logger:    'Accept': 'application/json'\n",
      "DEBUG:msrest.http_logger:    'Content-Type': 'application/json; charset=utf-8'\n",
      "DEBUG:msrest.http_logger:    'x-ms-client-request-id': 'c06ea38d-340e-45ee-a096-f5345462a56f'\n",
      "DEBUG:msrest.http_logger:    'User-Agent': 'python/3.6.10 (Linux-5.0.0-1028-azure-x86_64-with-debian-buster-sid) msrest/0.6.13 azureml._restclient/core.1.0.57'\n",
      "DEBUG:msrest.http_logger:Request body:\n",
      "DEBUG:msrest.http_logger:None\n",
      "DEBUG:msrest.universal_http:Configuring redirects: allow=True, max=30\n",
      "DEBUG:msrest.universal_http:Configuring request: timeout=100, verify=True, cert=None\n",
      "DEBUG:msrest.universal_http:Configuring proxies: ''\n",
      "DEBUG:msrest.universal_http:Evaluate proxies against ENV settings: True\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): eastus.modelmanagement.azureml.net:443\n",
      "DEBUG:urllib3.connectionpool:https://eastus.modelmanagement.azureml.net:443 \"GET /api/subscriptions/32cf04de-62b6-46b8-b31a-863d7fd95678/resourceGroups/azuremlresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/workspace/assets/4e40bbe0ed9e4642a872717c960ccaaa?api-version=2018-11-19 HTTP/1.1\" 200 None\n",
      "DEBUG:msrest.http_logger:Response status: 200\n",
      "DEBUG:msrest.http_logger:Response headers:\n",
      "DEBUG:msrest.http_logger:    'Date': 'Mon, 20 Apr 2020 09:42:26 GMT'\n",
      "DEBUG:msrest.http_logger:    'Content-Type': 'application/json; charset=utf-8'\n",
      "DEBUG:msrest.http_logger:    'Transfer-Encoding': 'chunked'\n",
      "DEBUG:msrest.http_logger:    'Connection': 'keep-alive'\n",
      "DEBUG:msrest.http_logger:    'Vary': 'Accept-Encoding'\n",
      "DEBUG:msrest.http_logger:    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\n",
      "DEBUG:msrest.http_logger:    'x-ms-client-request-id': 'c06ea38d-340e-45ee-a096-f5345462a56f'\n",
      "DEBUG:msrest.http_logger:    'x-ms-client-session-id': ''\n",
      "DEBUG:msrest.http_logger:    'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19'\n",
      "DEBUG:msrest.http_logger:    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\n",
      "DEBUG:msrest.http_logger:    'Content-Encoding': 'gzip'\n",
      "DEBUG:msrest.http_logger:Response content:\n",
      "DEBUG:msrest.http_logger:{\n",
      "  \"id\": \"4e40bbe0ed9e4642a872717c960ccaaa\",\n",
      "  \"name\": \"resnet_model\",\n",
      "  \"description\": \"resnet_model saved during run None in project None\",\n",
      "  \"artifacts\": [\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"prefix\": \"LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz\"\n",
      "    }\n",
      "  ],\n",
      "  \"tags\": null,\n",
      "  \"kvTags\": {},\n",
      "  \"properties\": {},\n",
      "  \"runid\": null,\n",
      "  \"projectid\": null,\n",
      "  \"meta\": null,\n",
      "  \"createdTime\": \"2020-04-20T09:40:01.5370733Z\"\n",
      "}\n",
      "DEBUG:azureml.AssetsClient.query_by_id-async:False:[STOP]\n",
      "DEBUG:msrest.universal_http.requests:Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\n",
      "DEBUG:urllib3.util.retry:Converted retries value: 3 -> Retry(total=3, connect=None, read=None, redirect=None, status=None)\n",
      "DEBUG:azureml.core.model:Asset has artifact {'additional_properties': {}, 'id': None, 'prefix': 'LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz'}\n",
      "DEBUG:azureml.core.model:Artifact has prefix id LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz\n",
      "DEBUG:azureml.ArtifactsClient:Fetching files for prefix in LocalUpload, 200420T093956-be2cbebc, resnet_model.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:azureml.ArtifactsClient.list_sas_by_prefix-async:True:[START]\n",
      "DEBUG:azureml._restclient.clientbase.WorkerPool:submitting future: _execute_with_base_arguments\n",
      "DEBUG:msrest.service_client:Accept header absent and forced to application/json\n",
      "DEBUG:azureml.ArtifactsClient.list_sas_by_prefix:Using basic handler - no exception handling\n",
      "DEBUG:msrest.universal_http.requests:Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\n",
      "DEBUG:azureml.ArtifactsClient.list_sas_by_prefix-async:True:[STOP]\n",
      "DEBUG:azureml.ArtifactsClient.list_sas_by_prefix.WaitingTask:[START]\n",
      "DEBUG:azureml.ArtifactsClient.list_sas_by_prefix.WaitingTask:Awaiter is ApiPagination\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:cli.azure.cli.core:Current cloud config:\n",
      "AzureCloud\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - Authority:Performing instance discovery: ...\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - Authority:Performing static instance discovery\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - Authority:Authority validated via static instance discovery\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - TokenRequest:Getting token from cache with refresh if necessary.\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - CacheDriver:finding with query keys: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - CacheDriver:Looking for potential cache entries: {'_clientId': '...', 'userId': '...'}\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - CacheDriver:Found 2 potential entries.\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - CacheDriver:Resource specific token found.\n",
      "DEBUG:adal-python:8d7751a0-20e0-4a4c-92fa-7865d9c5fea8 - CacheDriver:Returning token from cache lookup, AccessTokenId: b'FcU7/YFvV7OsI3mXIaHEOK+1MDQ9CH9hgni2i8EC8tk=', RefreshTokenId: b'9kJefConsGAGG6FoD0LFr4Bzi1GeBwtQ64HigSzzC2U='\n",
      "DEBUG:msrest.http_logger:Request URL: 'https://eastus.experiments.azureml.net/artifact/v2.0/subscriptions/32cf04de-62b6-46b8-b31a-863d7fd95678/resourceGroups/azuremlresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/workspace/artifacts/prefix/contentinfo/LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz'\n",
      "DEBUG:msrest.http_logger:Request method: 'GET'\n",
      "DEBUG:msrest.http_logger:Request headers:\n",
      "DEBUG:msrest.http_logger:    'Accept': 'application/json'\n",
      "DEBUG:msrest.http_logger:    'Content-Type': 'application/json; charset=utf-8'\n",
      "DEBUG:msrest.http_logger:    'x-ms-client-request-id': 'ad093d4a-b9e6-4123-ba3a-93b3f99b9237'\n",
      "DEBUG:msrest.http_logger:    'User-Agent': 'python/3.6.10 (Linux-5.0.0-1028-azure-x86_64-with-debian-buster-sid) msrest/0.6.13 azureml._restclient/core.1.0.57'\n",
      "DEBUG:msrest.http_logger:Request body:\n",
      "DEBUG:msrest.http_logger:None\n",
      "DEBUG:msrest.universal_http:Configuring redirects: allow=True, max=30\n",
      "DEBUG:msrest.universal_http:Configuring request: timeout=100, verify=True, cert=None\n",
      "DEBUG:msrest.universal_http:Configuring proxies: ''\n",
      "DEBUG:msrest.universal_http:Evaluate proxies against ENV settings: True\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): eastus.experiments.azureml.net:443\n",
      "DEBUG:urllib3.connectionpool:https://eastus.experiments.azureml.net:443 \"GET /artifact/v2.0/subscriptions/32cf04de-62b6-46b8-b31a-863d7fd95678/resourceGroups/azuremlresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/workspace/artifacts/prefix/contentinfo/LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz HTTP/1.1\" 200 None\n",
      "DEBUG:msrest.http_logger:Response status: 200\n",
      "DEBUG:msrest.http_logger:Response headers:\n",
      "DEBUG:msrest.http_logger:    'Date': 'Mon, 20 Apr 2020 09:42:26 GMT'\n",
      "DEBUG:msrest.http_logger:    'Content-Type': 'application/json; charset=utf-8'\n",
      "DEBUG:msrest.http_logger:    'Transfer-Encoding': 'chunked'\n",
      "DEBUG:msrest.http_logger:    'Connection': 'keep-alive'\n",
      "DEBUG:msrest.http_logger:    'Vary': 'Accept-Encoding'\n",
      "DEBUG:msrest.http_logger:    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\n",
      "DEBUG:msrest.http_logger:    'x-ms-response-type': 'standard'\n",
      "DEBUG:msrest.http_logger:    'x-ms-client-request-id': 'ad093d4a-b9e6-4123-ba3a-93b3f99b9237'\n",
      "DEBUG:msrest.http_logger:    'x-ms-client-session-id': ''\n",
      "DEBUG:msrest.http_logger:    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\n",
      "DEBUG:msrest.http_logger:    'Content-Encoding': 'gzip'\n",
      "DEBUG:msrest.http_logger:Response content:\n",
      "DEBUG:msrest.http_logger:{\n",
      "  \"value\": [\n",
      "    {\n",
      "      \"contentUri\": \"https://workspace2030360752.blob.core.windows.net/azureml/LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz?sv=2019-02-02&sr=b&sig=gfj8S5D%2FFjvI2RzyYN8qcQYJ0IJ37sellck0HZYPuxE%3D&st=2020-04-20T09%3A32%3A26Z&se=2020-04-20T17%3A42%3A26Z&sp=r\",\n",
      "      \"origin\": \"LocalUpload\",\n",
      "      \"container\": \"200420T093956-be2cbebc\",\n",
      "      \"path\": \"resnet_model.tar.gz\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "DEBUG:azureml.ArtifactsClient.list_sas_by_prefix.WaitingTask:[STOP]\n",
      "DEBUG:azureml.core.model:prefix id LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz has path resnet_model.tar.gz\n",
      "DEBUG:azureml.core.model:prefix to strip from path resnet_model.tar.gz is \n",
      "DEBUG:azureml.core.model:sas_to_download_path map is OrderedDict([('https://workspace2030360752.blob.core.windows.net/azureml/LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz?sv=2019-02-02&sr=b&sig=gfj8S5D%2FFjvI2RzyYN8qcQYJ0IJ37sellck0HZYPuxE%3D&st=2020-04-20T09%3A32%3A26Z&se=2020-04-20T17%3A42%3A26Z&sp=r', 'resnet_model.tar.gz')])\n",
      "DEBUG:azureml._file_utils.file_utils:downloading file to azureml-models/resnet_model/1/resnet_model.tar.gz, with max_retries: 3, stream: True, and protocol: https\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): workspace2030360752.blob.core.windows.net:443\n",
      "DEBUG:urllib3.connectionpool:https://workspace2030360752.blob.core.windows.net:443 \"GET /azureml/LocalUpload/200420T093956-be2cbebc/resnet_model.tar.gz?sv=2019-02-02&sr=b&sig=gfj8S5D%2FFjvI2RzyYN8qcQYJ0IJ37sellck0HZYPuxE%3D&st=2020-04-20T09%3A32%3A26Z&se=2020-04-20T17%3A42%3A26Z&sp=r HTTP/1.1\" 200 224608777\n",
      "DEBUG:azureml.core.model:Unpacking model azureml-models/resnet_model/1/resnet_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_path = Model.get_model_path(\"resnet_model\", _workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEURL = \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/220px-Lynx_lynx_poing.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:azureml.core.run:Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}, switching offline: False\n",
      "DEBUG:azureml.core.run:Could not load the run context and allow_offline set to False\n",
      "DEBUG:azureml.core.model:RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}\n",
      "DEBUG:azureml.core.model:version is None. Latest version is 1\n",
      "DEBUG:azureml.core.model:Found model path at azureml-models/resnet_model/1/model_resnet_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:71: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:71: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:514: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:514: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4076: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4076: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:171: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:171: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:178: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:178: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1811: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1811: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3900: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3900: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3904: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/deployment_aml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3904: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Always make sure you don't have any lingering notebooks running. Otherwise it may cause GPU memory issue.\n",
    "process_and_score = get_model_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = process_and_score({\"lynx\": open(\"220px-Lynx_lynx_poing.jpg\", \"rb\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will [build a docker image with this modle driver and other supporting files](03_BuildImage.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "deployment_aml",
   "language": "python",
   "name": "conda-env-deployment_aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
